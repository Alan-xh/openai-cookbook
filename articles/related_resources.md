# 来自网络的相关资源

人们正在编写出色的工具和论文来改进GPT的输出。这里有一些我们看到的很酷的：

## 提示库和工具（按字母顺序排列）

- **[Arthur Shield](https://www.arthur.ai/get-started)**: 一款付费产品，用于检测毒性、幻觉、提示注入等。
- **[Baserun](https://baserun.ai/)**: 一款付费产品，用于测试、调试和监控基于LLM的应用程序。
- **[Chainlit](https://docs.chainlit.io/overview)**: 一个用于制作聊天机器人界面的Python库。
- **[Embedchain](https://github.com/embedchain/embedchain)**: 一个用于管理和同步非结构化数据与LLM的Python库。
- **[FLAML (快速自动化机器学习和调优库)](https://microsoft.github.io/FLAML/docs/Getting-Started/)**: 一个Python库，用于自动选择模型、超参数和其他可调选项。
- **[Guidance](https://github.com/microsoft/guidance)**: 来自微软的有用Python库，使用Handlebars模板来交错生成、提示和逻辑控制。
- **[Haystack](https://github.com/deepset-ai/haystack)**: 开源的LLM编排框架，用于在Python中构建可定制的、生产就绪的LLM应用。
- **[HoneyHive](https://honeyhive.ai)**: 一个企业平台，用于评估、调试和监控LLM应用。
- **[LangChain](https://github.com/hwchase17/langchain)**: 一个流行的Python/JavaScript库，用于链接语言模型提示的序列。
- **[LiteLLM](https://github.com/BerriAI/litellm)**: 一个用于调用LLM API的简约Python库，具有统一的格式。
- **[LlamaIndex](https://github.com/jerryjliu/llama_index)**: 一个用于增强LLM应用的数据的Python库。
- **[LLMOps Database](https://www.reddit.com/r/LocalLLaMA/comments/1h4u7au/a_nobs_database_of_how_companies_actually_deploy/)**: 关于公司如何实际在生产中部署LLM的数据库。
- **[LMQL](https://lmql.ai)**: 一种用于LLM交互的编程语言，支持类型提示、控制流、约束和工具。
- **[OpenAI Evals](https://github.com/openai/evals)**: 一个用于评估语言模型和提示任务性能的开源库。
- **[Outlines](https://github.com/normal-computing/outlines)**: 一个Python库，提供了一种简化提示和约束生成的领域特定语言。
- **[Parea AI](https://www.parea.ai)**: 一个用于调试、测试和监控LLM应用的平台。
- **[Portkey](https://portkey.ai/)**: 一个用于LLM应用的可观察性、模型管理、评估和安全的平台。
- **[Promptify](https://github.com/promptslab/Promptify)**: 一个小型Python库，用于使用语言模型执行NLP任务。
- **[PromptPerfect](https://promptperfect.jina.ai/prompts)**: 一款用于测试和改进提示的付费产品。
- **[Prompttools](https://github.com/hegelai/prompttools)**: 用于测试和评估模型、向量数据库和提示的开源Python工具。
- **[Scale Spellbook](https://scale.com/spellbook)**: 一款用于构建、比较和发布语言模型应用的付费产品。
- **[Semantic Kernel](https://github.com/microsoft/semantic-kernel)**: 来自微软的Python/C#/Java库，支持提示模板化、功能链、向量化记忆和智能规划。
- **[Vellum](https://www.vellum.ai/)**: 一个用于实验、评估和部署高级LLM应用的付费AI产品开发平台。
- **[Weights & Biases](https://wandb.ai/site/solutions/llmops)**: 一款用于跟踪模型训练和提示工程实验的付费产品。
- **[YiVal](https://github.com/YiVal/YiVal)**: 一个用于调整和评估提示、检索配置和模型参数的开源GenAI-Ops工具，利用可定制的数据集、评估方法和进化策略。

## 提示指南

- **[Brex的提示工程指南](https://github.com/brexhq/prompt-engineering)**: Brex关于语言模型和提示工程的介绍。
- **[learnprompting.org](https://learnprompting.org/)**: 提示工程的入门课程。
- **[Lil'Log Prompt Engineering](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)**: OpenAI研究员对提示工程文献的回顾（截至2023年3月）。
- **[OpenAI Cookbook: 提高可靠性的技术](https://cookbook.openai.com/articles/techniques_to_improve_reliability)**: 关于提示语言模型的技术的稍旧回顾（2022年9月）。
- **[promptingguide.ai](https://www.promptingguide.ai/)**: 一个展示许多技术的提示工程指南。
- **[Xavi Amatriain的提示工程101](https://amatriain.net/blog/PromptEngineering) 和 [202高级提示工程](https://amatriain.net/blog/prompt201)**: 一个基本但有观点的提示工程介绍和一个包含许多高级方法的后续集合，以CoT开始。

## 视频课程

- **[Andrew Ng的DeepLearning.AI](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)**: 开发人员的提示工程短课程。
- **[Andrej Karpathy的Let's build GPT](https://www.youtube.com/watch?v=kCc8FmEb1nY)**: 详细探讨GPT背后的机器学习。
- **[DAIR.AI的提示工程](https://www.youtube.com/watch?v=dOxUroR57xs)**: 关于各种提示工程技术的1小时视频。
- **[Scrimba关于助手API的课程](https://scrimba.com/learn/openaiassistants)**: 关于助手API的30分钟互动课程。
- **[LinkedIn课程：提示工程入门：如何与AI对话](https://www.linkedin.com/learning/prompt-engineering-how-to-talk-to-the-ais/talking-to-the-ais?u=0)**: 提示工程的简短视频介绍

## 关于改进推理的先进提示论文

- **[思维链提示在大型语言模型中引发推理（2022）](https://arxiv.org/abs/2201.11903)**: 使用少量提示要求模型逐步思考可以改善它们的推理能力。PaLM在数学词问题（GSM8K）上的得分从18%提高到57%。
- **[自我一致性提高语言模型中的思维链推理（2022）](https://arxiv.org/abs/2203.11171)**: 通过多输出投票进一步提高准确性。在40个输出的投票中，PaLM在数学词问题上的得分从57%提高到74%，`code-davinci-002`从60%提高到78%。
- **[思维树：利用大型语言模型进行有意识的问题解决（2023）](https://arxiv.org/abs/2305.10601)**: 在逐步推理的树上搜索比投票思维链更有帮助。它提升了`GPT-4`在创意写作和填字游戏上的得分。
- **[语言模型是零样本推理者（2022）](https://arxiv.org/abs/2205.11916)**: 告诉指令遵循模型逐步思考可以提高它们的推理能力。它将`text-davinci-002`在数学词问题（GSM8K）上的得分从13%提高到41%。
- **[大型语言模型是人类级别的提示工程师（2023）](https://arxiv.org/abs/2211.01910)**: 自动搜索可能的提示找到了一个提升数学词问题（GSM8K）得分至43%的提示，比《语言模型是零样本推理者》中的人工编写的提示高出2个百分点。
- **[重新提示：通过Gibbs采样推断自动思维链提示（2023）](https://arxiv.org/abs/2305.09993)**: 自动搜索可能的思维链提示在几个基准上提高了ChatGPT的得分，范围为0-20个百分点。
- **[使用大型语言模型进行忠实推理（2022）](https://arxiv.org/abs/2208.14271)**: 通过结合替代选择和推理提示生成的思维链、选择何时停止选择-推理循环的停止模型、搜索多个推理路径的价值函数以及帮助避免幻觉的句子标签，可以改进推理。
- **[STaR：通过推理引导推理（2022）](https://arxiv.org/abs/2203.14465)**: 通过微调可以将思维链推理内置到模型中。对于有答案的任务，示例思维链可以通过语言模型生成。
- **[ReAct：在语言模型中同步推理和行动（2023）](https://arxiv.org/abs/2210.03629)**: 对于有工具或环境的任务，如果你规定性地交替**Re**asoning步骤（思考要做什么）和**Act**ing（从工具或环境中获取信息），思维链工作得更好。
- **[Reflexion：一个具有动态记忆和自我反思的自主代理（2023）](https://arxiv.org/abs/2303.11366)**: 带着之前失败的记忆重试任务可以改善后续的表现。
- **[Demonstrate-Search-Predict：为知识密集型NLP组合检索和语言模型（2023）](https://arxiv.org/abs/2212.14024)**: 通过“检索然后阅读”增强知识的模型可以用多跳搜索链来改进。
- **[通过多智能体辩论改进语言模型的事实性和推理能力（2023）](https://arxiv.org/abs/2305.14325)**: 在几个回合内生成几个ChatGPT智能体之间的辩论可以在各种基准上提高得分。数学词问题的得分从77%提高到85%。